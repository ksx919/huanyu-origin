# 幻语系统架构设计（Frontend + Backend + TTS）

> 版本：v1.0  ·  范围：`d:\HuanyuOrigin\Fronted\my-genshin-chat`、`d:\HuanyuOrigin\Huanyu`、`d:\HuanyuOrigin\GPT-SoVITS-TTS`
>
> 说明：本文档从架构与模块规格的角度描述系统的组成、职责分工、主要接口与数据流。

---

## 1. 总览

- 前端（Web 客户端）：`Fronted/my-genshin-chat`，基于 `Vue3 + Vite + TypeScript`，负责用户登录注册、文本聊天与语音通话的界面与交互。
- 后端（应用服务）：`Huanyu`，基于 `Java + Spring Boot`，负责用户与会话管理、WebSocket 语音通话、ASR/AI/TTS 调度、消息持久化与缓存。
- 语音合成服务（TTS）：`GPT-SoVITS-TTS`，基于 Python 的 GPT-SoVITS 推理栈，提供多角色的语音合成能力，后端通过内部接口进行调用。

### 1.1 技术栈与基础设施
- 前端：`Vue3`、`Vite`、`TypeScript`、`Axios`、`Pinia/自定义 store`、`WebSocket`。
- 后端：`Spring Boot`、`Redis`（会话与临时状态）、`MySQL`（持久化）、`WebSocket`、（AI 服务抽象）。
- TTS：`Python`、`GPT-SoVITS`、`BigVGAN`、`f5_tts`、`Whisper` 等依赖。

### 1.2 关键设计要点
- 语音通话的消息被标记为“临时（ephemeral）”，默认不入库；
- 语音识别（ASR）结束一个句子后触发 AI 回复；文本片段分段并串行进行 TTS，音频通过 WebSocket 以二进制流回传前端。
- 文本模式的聊天正常入库，避免语音聊天内容污染历史；对重复消息进行去重校验。

---

## 团队分工

### 成员一（江在程）
- 负责模块：Java 后端（`Huanyu`）,语音合成TTS（`GPT-SoVITS-TTS`）
- 主要任务：
  - 实现用户注册、登录、会话管理（基于 JWT）。
  - 处理 WebSocket 语音通话请求，协调 AI与TTS 服务。
  - 实现聊天消息的持久化存储与检索（MySQL）。
  - 提供 RESTful API 接口（`/chat`（部分）、`/user`(部分)、`/file`）。
  - 调用七牛云存储功能，实现用户头像、AI合成语音的上传与下载。
  - 负责添加jwtToken拦截器等逻辑，以及自定义业务异常处理和全局异常处理。
  - 部署MySQL、Redis服务于云服务器。
  - GPT-SoVITS为开源项目，本项目仅为提取其推理语音合成的接口，本人工作内容为提取语音合成接口并编写`GPT-SoVITS-TTS\start_all_characters.py`脚本用于启动项目。
  - 增加调用TTS合成结果的重试机制，并完成TTS合成的测试。
  - 使用开源项目训练TTS模型，使用的TTS的推理模型为个人训练得到。
- 交付物：
  - `Huanyu`项目代码（`Huanyu`）。
    - 用户注册登录模块开发、AI接口调用开发、提示词工程开发
    - 语音通话模块开发连接TTS服务、处理语音合成结果
    - 实现用户头像上传与下载功能
    - 实现用户角色选择与会话管理功能
    - 处理ai聊天记录存储功能实现
  - `GPT-SoVITS-TTS`项目代码（`GPT-SoVITS-TTS`）。
    - 提取语音合成接口，编写`start_all_characters.py`脚本用于启动项目
    - 实现多角色语音合成功能，每个角色有独立的语音合成接口
  - `Fronted`部分接口与后端连接的开发

### 成员二（李文杰）
- 负责模块：java后端，用户信息管理（密码/头像/昵称修改），内部服务通信接口，语音处理服务

- 主要任务：

1. **语音处理链路开发**  
   
   - 上传常用热词防止识别错误或不符合ai角色人设
   -   集成阿里云ASR服务，重构官方SDK实现：
     - 重写`AliyunAsrService`的process方法，封装语音分段上传、实时识别回调逻辑  
     - 将语音通话分块上传异步监听处理，实现实时语音转文字功能
     - 实现固定长度音频pcm文件多线程分块处理，所有线程识别完毕后再合成，提高固定长度语音识别效率
   
2. **AI模型调度与结果转发**  
   
   - 实现AI模型调度：  
     - 接收ASR结果后，通过解析sessionId字段获取type参数动态选择角色专属模型
     - 将AI生成结果同步发送至协作接口用于后续合成对应角色的语音
   - 新增异常熔断机制，当AI模型响应超时（>5s）时自动降级为默认回复  
   
3. **用户信息管理模块**  
   
   - 优化数据库存储：
   
     - 增加存储校验，解决流式传输造成的重复入库问题 
     - 使角色AI模型能够获取更多有用的历史数据，增强用户个性化使用体验
   
   - 完善`UserController`的`/update`相关接口：
   
     - 密码修改增加历史版本校验（禁止与最近更新的密码重复） 
   
     - 增加短期更新次数校验防止过度频繁操作、恶意更新带来的数据库压力
   
- 交付物：

  - `Huanyu`项目代码（`Huanyu`）。
    - 用户更新模块开发、阿里云识别API接口调用开发
    - 语音通话模块开发、实时生成语音文本以及对应的AI回复文本、处理AI回复文本
    - 实现用户头像、密码、昵称的更新功能
    - 优化ai聊天记录存储功能实现

### 成员三（刘镇源）
- 负责模块：前端应用 (`Fronted/my-genshin-chat`)
- 主要任务：
  - **构建完整的前端应用架构**
    - 基于 `Vue3 + Vite + TypeScript` 初始化并搭建整个前端项目。
    - 配置 `Vue Router` 实现多页面应用的路由管理（登录页、主页、个人中心）。
    - 搭建全局状态管理 `store`，负责在多组件间共享和持久化用户认证信息（Token、昵称等）。
    - 封装 `axios` 实例，配置请求拦截器以自动附加JWT认证头部。

  - **实现用户认证全流程界面**
    - 开发登录与注册的Tab切换界面。
    - 对接后端接口，实现获取图形验证码、发送邮箱验证码（包含60秒冷却倒计时）、用户注册和密码登录的完整逻辑。
    - 设计并实现个人中心页面，支持“点击修改”昵称、上传并更换用户头像、修改密码等功能。

  - **开发核心聊天界面与双模式交互**
    - 在文字聊天模式下，实现消息列表的渲染（区分用户和AI）、头像显示、文本输入、语音转文字输入、以及AI回复语音的播放功能。
    - 为实时语音模式搭建了通话界面框架，包括角色浮动头像和通话控制按钮。
  - **负责整体前端应用的UI/UX美化与交互优化**
    - 实现全局统一的视觉风格，包括毛玻璃背景、粒子动画等。
    - 为所有交互元素（如按钮、链接、头像）添加平滑的过渡（`transition`）和悬浮（`:hover`）动效，提升用户体验。
    - 解决并优化多处CSS布局问题，实现页面的动态高度平滑过渡、元素对齐等视觉细节。

- 交付物：
  - `Fronted`项目代码 (`Fronted/my-genshin-chat`)。
    - **用户认证模块**：包含登录/注册/验证码逻辑的 `Login.vue` 组件。
    - **个人中心模块**：包含用户信息展示、资料修改、头像上传逻辑的 `Profile.vue` 组件。
    - **核心聊天模块**：包含角色选择、双模式聊天界面、实时语音/文字消息交互逻辑的 `Home.vue` 组件。
    - **全局架构**：包含全局布局 `App.vue`、路由配置 `router/index.ts`、状态管理 `store/auth.ts` 等。


---

## 2. 前端模块规格（`Fronted/my-genshin-chat`）

### 2.1 路由与应用外壳
- `src/main.ts`：应用入口，挂载 `App.vue` 与路由。
- `src/router/index.ts`：路由定义（`/`、`/login`、`/profile` 等）。
- `src/App.vue`：全局布局与容器。

### 2.2 认证与状态管理
- `src/store/auth.ts`
  - 职责：保存 `token`、`nickname`、`email`、`avatar` 等用户信息，并提供 `login`/`logout` 方法。
  - 输入：登录成功的后端响应数据。
  - 输出：持久化到 `localStorage`（或内存），供后续 API 与页面使用。

### 2.3 网络与工具
- `src/utils/axios.ts`
  - 职责：封装 `Axios` 实例（`baseURL`、请求/响应拦截器、鉴权头部等）。
  - 对外：`http.get/post/...` 用于业务请求，如验证码、登录注册、聊天接口。

### 2.4 视图与交互
- `src/views/Login.vue`
  - 功能：登录、注册、邮箱验证码、图形验证码交互。
  - 接口：
    - `GET /user/captcha` 获取图形验证码；`POST /user/captcha/delete` 删除旧验证码。
    - `POST /user/email-code` 发送邮箱验证码（已改为点击后异步请求 + 即刻倒计时）。
    - `POST /user/register`、`POST /user/login`。
  - 额外逻辑：发送验证码按钮点击后即进入倒计时（60s），不等待后端响应；失败仅提示并刷新验证码，不影响倒计时。

- `src/views/Home.vue`
  - 功能：文本聊天与（潜在）语音入口，消息展示，角色选择与会话入口。
  - 与后端：HTTP 聊天接口（若有）与 WebSocket 语音通话端点。

- `src/views/Profile.vue`
  - 功能：用户资料展示与简单配置（如头像）。

### 2.5 资源与音频处理
- `public/audio-processor.js`
  - 作用：在浏览器端对音频数据进行预处理（采样率/PCM 格式等），为 WebSocket 推送二进制音频做准备。

### 2.6 前端对外接口与契约
- 登录与注册：
  - 请求：`email`、`password`、`nickname`、`emailCode`、`captchaId`、`captchaCode`。
  - 响应：`{ success, message?, data: { token, nickname, email, avatar } }`。
- 语音通话：
  - 启动：与后端约定 WebSocket 地址。首条 `TextMessage` 进行握手（如 `sessionId`、角色、模式）；随后推送 `BinaryMessage` PCM 音频。
  - 返回：
    - 文本消息：AI 回复的流式文本片段与状态（如 `audio_start` / `audio_end`）。
    - 二进制音频：TTS 生成的 PCM/OGG/WAV（依据约定）音频分片。

---

## 3. 后端模块规格（`Huanyu`）

> 基于 `Spring Boot`，包含 WebSocket 语音通话、ASR/AI/TTS 调度、消息存储与缓存等。

### 3.1 WebSocket 层
- `PcmAudioWebSocketHandler.java`
  - 职责：处理前端 WebSocket 的消息。
  - 行为：
    - `handleMessage`：
      - 先处理 `BinaryMessage`（音频数据），后处理 `TextMessage`（握手与 `sessionId` 设置、角色信息、临时会话标记）。
      - 首次音频可能在 `sessionId` 标记前到达；通过下游逻辑在首次音频接入时绑定 `sessionId`。
    - `afterConnectionClosed`：调用 `memoryStore.unmarkEphemeralSession(sessionId)`，并设置短暂保护期（Redis TTL）避免竞态导致误入库。

- `WebSocketSpeechTranscriber.java`
  - 职责：ASR（语音转文本）、触发 AI 回复、TTS 分段与串行音频回传。
  - 关键方法：
    - `process(byte[] data, String sessionId)`：实时音频处理，初始化与绑定 `sessionId`。
    - `onSentenceEnd`：句子结束后调用 `aiChatService.chat(sessionId, userText, characterId)`；进行句子去重（`processedSentenceIds`）。
    - `enqueueTtsSegment` / `streamTtsAndSend`：将 AI 文本分段、顺序进行 TTS，发送 `audio_start`/`audio_end` 文本并推送二进制音频。
    - `interrupt`：打断当前音频流。

### 3.2 会话与存储层
- `MyChatMemoryStoreImpl.java`
  - 职责：管理聊天窗口、临时会话标记、消息持久化与去重。
  - 临时会话（语音通话）设计：
    - Redis 键：
      - `chat:ephemeral:{sessionId}`（TTL 10 分钟）：语音会话期间设为临时；多实例共享。
      - 取消标记时设置“保护期”（TTL 3 秒）：规避连接关闭与入库之间的竞态。
      - `chat:ephemeral:msg:{sessionId}`（TTL 6 小时）：语音阶段消息哈希集合（类型+内容的 SHA-1），作为后续入库拦截依据。
    - `updateMessages(...)`：当 `isEphemeralSession(sessionId)` 为真时，跳过入库，并记录语音阶段的最新消息哈希。
    - `storeAllMessagesToDatabase(...)`：持久化前先判断当前窗口最后一条消息是否命中 `chat:ephemeral:msg:{sessionId}`；命中则跳过入库。
  - 消息去重与持久化：
    - 判断最后消息是否已存在于数据库；不存在则转换并写入（`convertSingleMessageToDb`）。
    - 根据 `sessionId` 与角色类型维护会话记录（`recordChatSession`）。

### 3.3 AI 服务抽象
- `aiChatService.chat(sessionId, userText, characterId)`（接口抽象）
  - 输入：会话 ID、用户文本、角色 ID/类型。
  - 输出：流式 AI 文本（逐 token/chunk），并通过 WebSocket 回传给前端。
  - 说明：实现可对接多种模型；该模块负责将文本划分为 TTS 片段并入队。

### 3.4 数据库与缓存
- MySQL：
  - 表（示例）：
    - `chat_session`：`id`, `session_id`, `user_id`, `character_type`, `created_at`, `updated_at`。
    - `chat_message`：`id`, `session_id`, `role`（user/ai/system）, `content`, `created_at`。
- Redis：
  - 会话临时标记与保护期、语音阶段消息哈希集合。

### 3.5 对外接口
- HTTP：
  - `/user/captcha`、`/user/captcha/delete`、`/user/email-code`、`/user/register`、`/user/login`。
  - 聊天接口（如文本模式）：`POST /chat`（示例，实际以后端实现为准）。
- WebSocket：
  - PCM 通道（路径以实际配置为准）：
    - 文本：握手/控制消息（如 `sessionId`、角色、`audio_start`/`audio_end`）。
    - 二进制：音频上行（PCM）与下行（TTS 生成）。

---

## 4. TTS 服务模块规格（`GPT-SoVITS-TTS`）

### 4.1 目录结构与核心模块
- `api.py` / `api_v2.py`：TTS 服务的对外入口（HTTP/内部 API）。
- `configs/tts_infer.yaml`：推理配置。
- `TTS_infer_pack/TTS.py`：TTS 推理主逻辑。
- `feature_extractor/`：音频特征提取。
- `BigVGAN/`、`f5_tts/`、`module/`：声学模型与相关组件。
- `start_all_characters.py`：按角色加载/启动的脚本工具。

### 4.2 接口契约（示例）
- `POST /tts`
  - 请求：`{ text, speakerId/characterId, language?, speed?, emotion? }`
  - 响应：音频字节或可下载地址；后端采用流式/分片方式回传至前端。

### 4.3 行为与约束
- 支持长文本切分与串行推流，避免一次性生成阻塞。
- 资源占用较高；建议单独容器/主机部署，并设置并发限制与缓存。

---

## 5. 端到端流程（Sequence）

### 5.1 登录/注册
1. 前端在 `Login.vue` 发起验证码与登录/注册请求；验证码按钮点击即进入倒计时，后端请求后台异步。
2. 后端校验并返回 `{ token, nickname, email, avatar }`。
3. 前端通过 `authState.login(...)` 存储会话并跳转主页。

### 5.2 文本聊天
1. 前端调用后端聊天接口（或使用已存在的 WebSocket 文本模式）。
2. 后端调用 `aiChatService.chat(...)` 获取流式回复；不涉及临时会话标记。
3. `MySQL` 按窗口与去重策略进行持久化。

### 5.3 语音通话
1. 前端建立 WebSocket，发送握手 `TextMessage`（包含 `sessionId` 等）；随后推送 `BinaryMessage`（PCM 音频）。
2. 后端 `WebSocketSpeechTranscriber` 进行 ASR；句子结束时触发 `aiChatService.chat(...)`。
3. AI 文本分段入队、串行进行 TTS；通过 WebSocket 回传 `audio_start`/`audio_end` 文本与二进制音频。
4. 会话期间在 Redis 设 `chat:ephemeral:{sessionId}` 标记；并记录语音阶段消息哈希到 `chat:ephemeral:msg:{sessionId}`。
5. 连接关闭后短暂保护期仍在；任何命中哈希的消息均被拦截，不入库。

---

## 6. 部署与运行

### 6.1 依赖
- 数据库：`MySQL`（建议 8.x）。
- 缓存：`Redis`（建议启用持久化与哨兵/集群）。
- TTS：`Python 3.10+`，依赖按 `requirements.txt` 与各模型说明安装。

### 6.2 启动（示例）
- 前端：
  - `npm install`
  - `npm run dev`
- 后端：
  - 配置 `application.yml`（数据库/Redis/端口/WS 路径等）
  - `mvn spring-boot:run`
- TTS：
  - `pip install -r requirements.txt`
  - `python api.py`（或 `api_v2.py`）

### 6.3 配置项（示例）
- 前端 `.env*`：`VITE_API_BASE_URL`、`VITE_WS_URL` 等。
- 后端：
  - Redis 键前缀与 TTL：
    - `chat:ephemeral:{sessionId}` → 10 分钟
    - 取消保护期 → 3 秒
    - `chat:ephemeral:msg:{sessionId}` → 6 小时
  - 数据库连接、最大连接数、慢查询日志。
- TTS：
  - 语速/情感、多角色音色、并发与队列长度。

---

## 7. 安全与稳定性
- 认证：前端在 `Axios` 添加 `Authorization` 头；后端验证 Token 并限制接口权限。
- 速率限制：对 `/user/email-code`、聊天接口与 TTS 调用增加频控与防刷。
- 观察性：统一日志（语音阶段哈希命中、会话标记与取消、去重命中等），便于排查。
- 容错：对 WebSocket 的异常与断开进行重试与保护期处理；多实例通过 Redis 保持一致性。

---

## 8. 后续优化建议
- 将 HTTP 文本聊天与 WebSocket 语音通道的会话标记统一在一个入口，避免双通道并发导致的竞态。
- 在 `WebSocketSpeechTranscriber.onSentenceEnd` 增加更细粒度的去重键（包含来源与时间片），降低误判概率。
- 为 TTS 层增加结果缓存（文本→音频哈希），加速常见句子的合成。
- 为前端语音通话提供显式的来源标记（`voice`/`text`），用于后端更精确的持久化策略。

---

## 9. 术语表
- ASR：Automatic Speech Recognition，语音识别。
- TTS：Text-To-Speech，文本转语音。
- Ephemeral：临时会话；在语音通话期间产生的消息不落库。
- Grace TTL：保护期；用于规避连接关闭与最后一次写入的竞态。